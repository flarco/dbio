# leave this alone, unless you want to change the JARs
drivers:
  oracle:
    path: jars/ojdbc6-11.2.0.3.jar
    class: oracle.jdbc.driver.OracleDriver
  sqlserver:
    path: jars/jtds-1.3.1.jar
    class: net.sourceforge.jtds.jdbc.Driver
  postgresql:
    path: jars/postgresql-9.4.1207.jre7.jar
    class: org.postgresql.Driver
  mysql:
    path: jars/mysql-connector-java-6.0.6.jar
    class: com.mysql.jdbc.Driver
  sqlite:
    path: jars/sqlite-jdbc-3.23.1.jar
    class: org.sqlite.JDBC

# Here enter your database profiles, use proper JDBC URLs
# databse type include: oracle, postgresql, sqlserver, hive, spark
databases:
  EDW1:
    name: EDW1
    host: edw1
    port: 1521
    service: edw1_service
    user: user
    password: password
    type: oracle
    url: "jdbc:oracle:thin:@//edw1:1521/edw1_service"

  PG1:
    name: PG1
    host: pg1
    database: db1
    port: 5432
    user: user
    password: password
    sslmode: disable
    type: postgresql
    url: "jdbc:postgresql://host:port/database?&ssl=false"

  MSSQL1:
    name: MSSQL1
    host: mssql1
    database: master
    port: 1433
    user: user
    password: password
    odbc_driver: ODBC Driver 13 for SQL Server
    type: sqlserver
    url: "jdbc:jtds:sqlserver://mssql1:1433/master;user=user;password=password;instance=;useNTLMv2=true;domain=workgroup"

  SPARK_LOCAL:
    name: SPARK_LOCAL
    user: user
    hive_enabled: false
    spark_home: /path/spark-2.2.0-bin-hadoop2.7
    type: spark

  SPARK_HIVE_21:
    name: SPARK_HIVE
    user: user
    hive_enabled: true
    spark_home: /path/spark-2.1.0-bin-hadoop2.7
    type: spark

  SPARK_HIVE:
    name: SPARK_HIVE
    user: user
    hive_enabled: true
    spark_home: /path/spark-2.2.0-bin-hadoop2.7
    type: spark

  PG_TEST:
    name: PG_TEST
    host: localhost
    database: test_db
    port: 35432
    user: user
    password: password
    sslmode: disable
    type: postgresql
    url: "jdbc:postgresql://localhost:35432/test_db?&ssl=false"
  
  ORCL_TEST:
    name: ORCL_TEST
    host: localhost
    port: 31521
    sid: xe
    user: system
    password: oracle
    type: oracle
    url: "jdbc:oracle:thin:@//localhost:31521//xe"

  TESTS:
    EDW1:
      object: SCHEMA1.OBJECT1

environment:
  ETL_TEMP_DIR: /tmp

variable:
  hive_cmd: hive -e "set hive.cli.print.header=true; {sql}" | sed "s/\\"/\\"\\"/g" | sed "s/\\t/\\",\\"/g" | sed "s/^/\\"/g" | sed "s/$/\\"/g" | sed "s/\\"NULL\\"/\\"\\"/g"
  beeline_cmd: beeline -u "jdbc:hive2://hivehost:10000/" --outputformat=tsv --nullemptystring=true --incremental=true -e "set hive.cli.print.header=true; {sql}" | sed "s/\\"/\\"\\"/g" | sed "s/'\\t'/\\",\\"/g" | sed "s/^'/\\"/g" | sed "s/'$/\\"/g"
  tmp_folder: /tmp

spark-conf:
  # spark.master: 'yarn':
  spark.master: local[2]
  # spark.ui.port: '4040'
  # spark.cores.max: '2'
  # spark.yarn.queue: long
  # spark.driver.memory: 1g
  # spark.driver.maxResultSize: 2g
  # spark.driver.cores: '2'
  # spark.executor.memory: 500m
  # spark.executor.instances: '2'
  # spark.executor.cores: '1'
  # spark.sql.shuffle.partitions: 6
  spark.sql.broadcastTimeout: 900
  spark.sql.tungsten.enabled: "true"
  spark.io.compression.codec: snappy
  spark.rdd.compress: "true"
  spark.streaming.backpressure.enabled: "true"
  spark.sql.parquet.compression.codec: snappy
  # spark.local.dir: /tmp/spark_temp
  spark.sql.crossJoin.enabled: "true"
  # spark.driver.extraClassPath: jars/ojdbc6.jar
  # "spark.eventLog.enabled": "true"
